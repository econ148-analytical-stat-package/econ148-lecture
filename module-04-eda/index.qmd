---
title: ". "
title-slide-attributes:
  data-background-image: "plot/module-5.png"
  data-background-size: "cover"
format: 
  revealjs:
    theme: [simple, custom.scss]
    preview-links: true
    code-fold: false
    code-summary: "code"
    chalkboard: true
    slide-number: true
    footer: "Econ 148: Analytical and statistical packages for economics 1"
    quiz:
      defaultCorrect: "Correct!"
      defaultIncorrect: "Incorrect!"
revealjs-plugins:
  - quiz
engine: knitr
from: markdown+emoji
editor: visual
---

```{r}
#| echo: false
#| include: false
knitr::opts_chunk$set(comment = "", 
                      collapse = TRUE,
                      fig.align = "center",
                      fig.width = 8,
                      fig.height = 7
                      )

## working directory
# setwd("C:/Users/chris/Documents/Github-repository/econ148-lecture/module-04-eda")

setwd("c:\\Users\\viser\\OneDrive\\Dokumen\\Github repository\\econ148-lecture\\module-04-eda")

## Libraries
library(tidyverse)
library(glue)
library(patchwork)

# reading data
wildlife_impacts <- read_csv("data/wildlife_impacts.csv")
days_to_ship <- tibble(
  order = seq(12),
  warehouseA = c(3,3,3,4,4,4,5,5,5,5,5,5),
  warehouseB = c(1,1,1,3,3,4,5,5,5,6,7,10))

# setting the theme
theme_set(theme_bw(base_size = 18)) # Set theme for all ggplots

```

## Lessons

-   

    -   Overview of EDA
    -   Examining numerical data
    -   Considering categorical data
    -   Centrality and variability
    -   Amounts and proportions
    -   Comparisons
    -   Trends

# Lesson 1: What is EDA?

## EDA: an introduction

-   EDA is an iterative cycle that helps you understand what your data says. It involves:

    -   Generate questions about your data
    -   Search for answers by visualizing, transforming, and modeling your data
    -   Use what you learn to refine your questions and/or generate new questions

## EDA: an introduction

Your goal during EDA is to develop an understanding of your data.

> “Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise.” — John Tukey

## EDA: two useful questions

There is no rule about which questions you should ask to guide your research. However, two questions are particularly useful:

1.  What type of variation occurs within my variables?

2.  What type of covariation occurs between my variables?

## Is EDA a tool for discovery or confirmation? {.quiz-question}

-   [Discovery]{.correct data-explanation="Correct! EDA is a tool for discovery; in fact, EDA is one of the most fruitful tools for discovery in science. We’ll focus on discovery throughout this primer, but remember that you should test any pattern that you discover before you rely on it."}

-   [Confirmation]{data-explanation="Not quite. EDA reveals patterns, but it does not confirm that those patterns exist beyond your data set."}

## When you begin to explore data, is it better to formulate one or two high-quality questions to ask, or many, many questions to explore? {.quiz-question}

-   [One or two high-quality questions]{data-explanation="Not quite. It is hard to spot useful questions ahead of time because you don’t know which discoveries are waiting in your data."}

-   [Many, many questions]{.correct data-explanation="Correct! Each question you ask creates a new opportunity to discover something surprising. You can lead yourself to high-value questions by iterating on questions that reveal unexpected results."}

# Lesson 2: Examining numerical data

## scatter plots

```{r}
#| echo: false
knitr::include_graphics("plot/loan_scatter.png")
```

-   

    -   many borrowers with an income below \$100,000
    -   a handful of borrowers with income above \$250,000

## scatter plots: R codes

``` r
loan50 |> 
  mutate(total_income = total_income / 1000) |> 
  mutate(loan_amount = loan_amount / 1000) |>
  ggplot(aes(total_income, loan_amount)) +
  geom_point(
    size = 3, 
    color = "#377eb8"
  ) +
  scale_x_continuous(
    breaks = seq(0, 300, 50), 
    labels = scales::label_currency(suffix = "K"), 
    limits = c(0, 350), 
    expand = c(0, 0)
  ) +
  scale_y_continuous(
    breaks = seq(0, 40, 10), 
    labels = scales::label_currency(suffix = "K"), 
    limits = c(0, 42), 
    expand = c(0, 0)) +
  coord_cartesian(clip = "off") +
  labs(x = "Total Income", 
       y = "Loan Amount",
       title = "Scatter Plot of Total Income vs. Loan Amount"
      )
```

## scatter plots

```{r}
knitr::include_graphics("plot/poverty_scatter.png")
```

-   

    -   The relationship is nonlinear, as highlighted by the dashed line.
    -   What implications can you draw from this pattern?

::: notes
1.  Inverse relationship: As poverty rates increase, median household income decreases, following a clear downward trend shown by the dashed curve.

2.  Concentration pattern: Most counties cluster in the lower-left region (poverty rates between 5-20% and incomes between \$40K-\$60K), indicating this is the typical range for U.S. counties.

3.  Inverse relationship: As poverty rates increase, median household income decreases, following a clear downward trend shown by the dashed curve.

4.  Concentration pattern: Most counties cluster in the lower-left region (poverty rates between 5-20% and incomes between \$40K-\$60K), indicating this is the typical range for U.S. counties.
:::

## scatter plots: R codes

``` r
county |> 
  mutate(median_hh_income = median_hh_income / 1000) |>
  ggplot(aes(poverty, median_hh_income)) +
  geom_point(
    size = 3, 
    color = "#377eb8", 
    alpha = 0.8
  ) +
  geom_point(
    size = 0.5, 
    color = "gray40"
  ) +
  geom_smooth(
    color = "grey30", 
    lty = "dashed"
  ) +
  scale_y_continuous(
    breaks = seq(0, 130, 20), 
    labels = scales::label_currency(suffix = "K"), 
    limits = c(0, 130), 
    expand = c(0, 0)
  ) +
  scale_x_continuous(
    breaks = seq(0, 50, 10), 
    labels = scales::label_number(suffix = "%"), 
    limits = c(0, 50), 
    expand = c(0, 0)
  ) +
  coord_cartesian(clip = "off") +
  labs(x = "Poverty Rate (%)", 
       y = "Median Household Income",
       title = "Scatter Plot of Poverty Rate vs. Median Household Income"
      )
```

## scatter plots

```{r}
knitr::include_graphics("plot/population_change_scatter.png")
```

-   

    -   

        (a) Scatter plot of population change against the population before the change.

    -   

        (b) A scatter plot of the same data but where the population size has beenlog-transformed.

    -   What can we infer from these plots?

    -   Why log transformation is important?

::: notes
1.  

    (a) The untransformed plot shows extreme compression - nearly all counties are squeezed into the left side near 0. This makes it impossible to see patterns or relationships for the vast majority of counties

2.  The log₁₀ transformation spreads out the data points across the entire plot. Now we can clearly see the relationship between population and population change for ALL counties

3.  Large counties tend to have stable, modest population changes (clustered around 0%). Small to medium counties show much wider variation (both growth and decline)

4.  Why log transformation is important? It helps to reveal patterns in data that span several orders of magnitude, making it easier to analyze and interpret relationships that would otherwise be obscured.
:::

## scatter plots: R codes

``` r
p_231 <- 
  county |> 
  mutate(pop2017 = pop2017 / 1e6) |> 
  ggplot(aes(pop2017, pop_change)) +
  geom_point(
    color = "#377eb8", 
    size = 3, 
    alpha = 0.7
  ) +
  scale_x_continuous(
    breaks = seq(0, 10, 2), 
    limits = c(0, 10), 
    expand = c(0, 0), 
    labels = scales::label_number(suffix = "m")
  ) +
  scale_y_continuous(
    labels = scales::label_number(suffix = "%")
  ) +
  coord_cartesian(clip = "off") +
  labs(x = "(a) Population before change (m = millions)", 
       y = "Population Change (%)") +
  plot_theme

p_232 <- 
  county |> 
  mutate(pop2017 = pop2017 / 1e6) |> 
  ggplot(aes(pop2017, pop_change)) +
  geom_point(
    color = "#377eb8", 
    size = 3, 
    alpha = 0.7
  ) +
  scale_y_continuous(labels = scales::label_number(suffix = "%")) +
  scale_x_log10() +
  coord_cartesian(clip = "off") +
  labs(x = TeX("(b) $\\log_{10}$ Population before change (m = millions)"), 
       y = "Population Change (%)") +
  plot_theme

p_c_233 <- p_231 + p_232 + plot_layout(ncol = 2)
```

## Centrality (aka the "Average" value)

A single number representing the *middle* of a set of numbers

<br>

::: incremental
-   **Mean**: $\frac{\text{Sum of values}}{\text{# of values}}$

-   **Median**: "Middle" value (50% of data above & below)

-   **Mode**: Most frequent value (usually for categorical data)
:::

## Centrality (aka the "Average" value)

### Mean is not the always "best" choice

<br>

::::: columns
::: {.column width="40%"}
```{r}
#| echo: true

wildlife_impacts %>%
    filter(! is.na(height)) %>%
    summarise(
      mean = mean(height),
      median = median(height))
```

Percent of data below mean:

```{r}
#| echo: true

percentiles <- ecdf(wildlife_impacts$height)
meanP <- percentiles(mean(wildlife_impacts$height, na.rm = TRUE))
paste0(round(100*meanP, 1), '%')
```
:::

::: {.column width="60%"}
```{r}
knitr::include_graphics("plot/wildlife_impacts_hist.png")
```
:::
:::::

## dot plots

```{r}
knitr::include_graphics("plot/interest_rate_dotplot.png")
```

-   

    -   A dot plot is a one-variable scatterplot; an example using the interest rate of 50 loans above.
    -   Sometimes two variables are one too many: only one variable may be of interest.

## dot plots: R codes

``` r
loan50 |>
  ggplot(aes(x = interest_rate)) +
  geom_dotplot(
    binwidth = 1, 
    method = "histodot",
    fill = "#5A9BD5", 
    color = "#5A9BD5",
    dotsize = 0.8,
    stackratio = 1.2
  ) +
  geom_point(
    aes(y = -0.05, x = mean(loan50$interest_rate)),
    color = "red",
    size = 4,
    shape = 17,
    fill = "red",
    stroke = 5
  ) +
  geom_hline(yintercept = 0, color = "gray60") +
  scale_y_continuous(NULL, breaks = NULL) +
  scale_x_continuous(
    breaks = seq(5, 30, 5),
    labels = scales::percent_format(scale = 1),
    limits = c(5, 30)
  ) +
  coord_cartesian(ylim = c(-0.05, 1), clip = "off") +
  labs(x = "Interest Rate, Rounded to Nearest Percent") 
```

## histogram and shapes

```{r}
knitr::include_graphics("plot/interest_rate_histogram.png")
```

-   

    -   histograms provide a view of data density
    -   more loans with rates between 5% and 10% than loans with rates between 20% and 25%
    -   What key patterns can histograms reveal about data?


::::: columns
::: {.column width="50%"}
**Histograms**:

-   Skewness

-   Number of modes

<br>

**Boxplots**:

-   Outliers

-   Comparing variablesn
:::

::: {.column width="50%"}
```{r}
knitr::include_graphics("plot/eda-boxplot.png")
```
:::
:::::

## **Histogram**: Identify Skewness & \# of Modes

::::: columns
::: {.column width="50%"}
**Summarise**:

-   Mean, median, sd, range, & IQR:

```{r}
summary(wildlife_impacts$height)
```
:::

::: {.column width="50%"}
**Visualize**:

-   Histogram (identify skewness & modes)

```{r wildlife-height-hist, fig.width=7, fig.height=5, fig.align='center'}
ggplot(wildlife_impacts) +
  geom_histogram(aes(x = height), bins = 50) + #<<
  labs(x = 'Height (ft)', y = 'Count')
```
:::
:::::

## Historgam and shape: Skewness & \# of Modes

::::: columns
::: {.column width="50%"}
**Height**

```{r, ref.label="wildlife-height-hist", fig.width=7, fig.height=5, fig.align='center'}
```
:::

::: {.column width="50%"}
**Speed**

```{r wildlife-speed-hist, fig.width=7, fig.height=5, fig.align='center'}
ggplot(wildlife_impacts) +
  geom_histogram(aes(x = speed), bins = 50) + #<<
  labs(x = 'speed (mph)', y = 'Count')
```
:::
:::::


## histogram and shapes

```{r}
knitr::include_graphics("plot/histogram_modal_comparison.png")
```

-   

    -   modes in histograms tell us how many “centers of activity” exist in the data.
    -   they help uncover structure, complexity, and potential subgroup differences that a simple average or variance might miss.

## histrogram comparison: R codes

``` r
# histogram comparison: unimodal, bimodal, multimodal
set.seed(123)

# Generate equal-sized samples (500 each)
unimodal   <- rnorm(10000, mean = 10, sd = 2)
bimodal    <- c(rnorm(5000, mean = 5, sd = 1),
                rnorm(5000, mean = 8.5, sd = 1))
multimodal <- c(rnorm(3333, mean = 5,  sd = 1),
                rnorm(3333, mean = 8.5, sd = 1),
                rnorm(3334, mean = 12, sd = 1))

# Combine into one data frame
data <- bind_rows(
  data.frame(value = unimodal,   type = "Unimodal"),
  data.frame(value = bimodal,    type = "Bimodal"),
  data.frame(value = multimodal, type = "Multimodal")
) |> 
  tibble() |> 
  mutate(type = factor(type, levels = c("Unimodal", "Bimodal", "Multimodal")))

# Plot histograms side-by-side
ggplot(data, aes(x = value)) +
  geom_histogram(bins = 35, fill = "steelblue", color = "white", boundary = 0) +
  facet_wrap(~ type, nrow = 1) +
  labs(x = "Value",
       y = "Frequency") +
  plot_theme + 
  theme(strip.text = element_text(size = 16))
```

## Variability ("spread")

-   **Standard deviation**: distribution of values relative to the mean

    -   $s = \sqrt{\frac{\sum_{i=1}^{N}(x_i - \bar{x})^2}{N - 1}}$

-   **Interquartile range (IQR)**: $Q_3 - Q_1$ (middle 50% of data)

-   **Range**: max - min

## Variability ("spread")

-   Complaints are coming in about orders shipped from warehouse B, so you collect some data.

-   ... here **averages** are misleading

::::: columns
::: {.column width="50%"}
```{r}
#| echo: true
days_to_ship
```
:::

::: {.column width="50%"}
``` {.r code-line-numbers="5-6"}
days_to_ship |> 
  pivot_longer(-order, names_to = "warehouse", values_to = "days") |> 
  group_by(warehouse) |>
  summarise(
    mean = mean(days),
    median = median(days))
```

```{r}
days_to_ship |> 
  pivot_longer(-order, names_to = "warehouse", values_to = "days") |> 
  group_by(warehouse) |>
  summarise(
    mean = mean(days),
    median = median(days))
```
:::
:::::

## Variability ("spread")

::::: columns
-   Complaints are coming in about orders shipped from warehouse B, so you collect some data:

-   **variability** reveals difference in days to ship

::: {.column width="50%"}
```{r}
#| echo: true
days_to_ship
```
:::

::: {.column width="50%"}
``` {.r code-line-numbers="5-8"}
days_to_ship |> 
  pivot_longer(-order, names_to = "warehouse", values_to = "days") |> 
  group_by(warehouse) |>
  summarise(
    mean = mean(days),
    sd = sd(days),
    iqr = IQR(days),
    range = max(days) - min(days))
```

```{r}
days_to_ship |> 
  pivot_longer(-order, names_to = "warehouse", values_to = "days") |> 
  group_by(warehouse) |>
  summarise(
    mean = mean(days),
    sd = sd(days),
    iqr = IQR(days),
    range = max(days) - min(days))
```
:::
:::::

## Variability ("spread")

<br>

```{r}
knitr::include_graphics("plot/days_to_ship.png")
```


## Variance and standard deviation

:::: columns
:::  {.column width="60%"}
![](plot/variance_standard_deviation.png){width="80%" height="80%" fig-align="center"}
:::

:::  {.column width="40%"}
-   
    -   Low variance: tightly clustered around the mean
    -   Medium variance: moderately spread
    -   High variance: widely spread
    -   these plots tell us whether values cluster tightly around the mean (predictable) or spread widely (uncertain).
:::
::::


## Box plots, quartiles, and median

**Mean** and **standard deviation** are sensitive to outliers

-   **Outliers**: $Q_1 - 1.5 IQR$ \* $Q_3 + 1.5 IQR$

-   **Extreme values**: $Q_1 - 3 IQR$ \* $Q_3 + 3 IQR$

<br>

::::: columns
::: {.column width="50%"}
```{r}
#| echo: true
data1 <- c(3,3,4,5,5,6,6,7,8,9)
```

-   Mean: `r round(mean(data1), 2)`

-   Standard deviation: `r round(sd(data1), 2)`

-   Median: `r median(data1)`

-   IQR: `r IQR(data1)`
:::

::: {.column width="50%"}
```{r}
#| echo: true
data2 <- c(3,3,4,5,5,6,6,7,8,20)
```

-   Mean: `r mean(data2)`

-   Standard deviation: `r round(sd(data2), 2)`

-   Median: `r median(data2)`

-   IQR: `r IQR(data2)`\
:::
:::::


## Box plots, quartiles, and median

<br>

![](plot/boxplot-iqr.png){width="70%" height="70%" fig-align="center"}

::: {style="font-size: 70%; text-align: center;"}
Source: [Data Science Discovery](https://discovery.cs.illinois.edu/learn/Exploratory-Data-Analysis/Quartiles-and-Box-Plots/)
:::


## Identifying outliers

::::: columns
::: {.column width="50%"}
**Height**

```{r wildlife-height-boxplot, fig.width=7, fig.height=4, fig.align='center'}
ggplot(wildlife_impacts) +
    geom_boxplot(aes(x = height)) + #<<
    labs(x = 'Height (ft)', y = NULL)
```
:::

::: {.column width="50%"}
**Speed**

```{r wildlife-speed-boxplot, fig.width=7, fig.height=4, fig.align='center'}
ggplot(wildlife_impacts) +
    geom_boxplot(aes(x = speed)) + #<<
    labs(x = 'Speed (mph)', y = NULL)
```
:::
:::::

## Boxplot and histogram

::::: columns
::: {.column width="50%"}
**Histogram**

-   Skewness
-   Modes

```{r, ref.label="wildlife-speed-hist", echo=FALSE, fig.width=7, fig.height=5, fig.align='center'}
```
:::

::: {.column width="50%"}
**Boxplot**

-   Outliers

<br><br>

```{r, ref.label="wildlife-speed-boxplot", echo=FALSE, fig.width=7, fig.height=5, fig.align='center'}
```
:::
:::::


## Outliers

Robust statistics for continuous data (less sensitive to outliers)

-   **Centrality**: use *median* rather than *mean*

-   **Variability**: use *IQR* rather than *standard deviation*

## "Visualizing data helps us think"

```{r}
#| echo: true
anscombe |> tibble()
```

```{r}
#| echo: false
anscombe_summary_stats <- 
  anscombe |> 
  psych::describe() |> 
  select(mean, sd) |> 
  # tranform to column iwth rownames as column
  rownames_to_column("variable") |> 
  tibble() |> 
  pivot_longer(cols = c(mean, sd), names_to = "statistic", values_to = "value") |> 
  pivot_wider(names_from = variable, values_from = value)
```

<br>

```{r}
#| echo: true
anscombe_summary_stats
```

## Anscombe's Quartet

-   Stephen Few (2009, p6)

```{r}
knitr::include_graphics("plot/p_corr_anscombe.png")
```

## Data types determines how to summarize it

<br>

+-----------------------+----------------------+------------------------------------+
| Nominal (categorical) | Ordinal (categorical | Numerical (continuous)             |
+=======================+======================+====================================+
| **Measures**          | **Measures**         | **Measures**                       |
|                       |                      |                                    |
| -   Frequency counts  | -   Frequency counts | -   Mean, median                   |
| -   proportions       | -   proportions      | -   Range, standard deviation, IQR |
|                       | -   Median, mode     |                                    |
|                       | -   IQR              |                                    |
+-----------------------+----------------------+------------------------------------+
| **Charts**            | **Charts**           | **Charts**                         |
|                       |                      |                                    |
| -   Bars              | -   Bars             | -   Histogram                      |
|                       |                      | -   Boxplot                        |
+-----------------------+----------------------+------------------------------------+



# Lesson 3: Considering categorical data

## Summarizing Nominal data

::::: columns
::: {.column width="50%"}
Summarize with counts/ percentages

```{r}
#| echo: true

wildlife_impacts |> 
  count(operator, sort = TRUE) |> 
  mutate(percent = n / sum(n))
```
:::

::: {.column width="50%"}
Visualize with bars

```{r}
#| echo: true
#| eval: false

wildlife_impacts |> 
  count(operator, sort = TRUE) |> 
  ggplot(aes(x = fct_reorder(operator, n), y = n)) +
  geom_col() +
  coord_flip() +
  labs(x = "Operator", y = "Count") +
  theme_minimal()
```

```{r}
knitr::include_graphics("plot/nominal_barplot.jpeg")
```
:::
:::::

## Summarizing Ordinal data

::::: columns
::: {.column width="50%"}
Summarize: counts/ percentages

```{r}
#| echo: true
wildlife_impacts |> 
  count(incident_month, sort = TRUE) |> 
  mutate(percent = n / sum(n))
```
:::

::: {.column width="50%"}
Visualize: bars

```{r}
#| echo: true
#| eval: false

wildlife_impacts |> 
  count(incident_month, sort = TRUE) |> 
  ggplot(aes(x = as.factor(incident_month), y = n)) +
  geom_col() +
  labs(x = "Incident Month", y = "Count") 
```

```{r}
knitr::include_graphics("plot/ordinal_barplot.jpeg")
```
:::
:::::
